{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import mod\n",
    "from telnetlib import DM\n",
    "from turtle import mode\n",
    "from unicodedata import name\n",
    "import gym\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "from scipy import stats\n",
    "from statistics import mean \n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "import itertools\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "def get_env_name(name):\n",
    "    if ('humanoid' in name) or ('Humanoid' in name):\n",
    "        return 'Humanoid-v3'\n",
    "    if ('halfcheetah' in name) or ('HalfCheetah' in name):\n",
    "        return 'HalfCheetah-v3'\n",
    "    if ('ant' in name) or ('Ant' in name):\n",
    "        return 'Ant-v3'\n",
    "    if ('hopper' in name) or  ('Hopper' in name) :\n",
    "        return 'Hopper-v3'\n",
    "    if ('walker' in name) or ('Walker' in name) :\n",
    "        return 'Walker2d-v3'\n",
    "    return 'unknown'\n",
    "\n",
    "def mlp(sizes, activation, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes)-1):\n",
    "        act = activation if j < len(sizes)-2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class PPO_Actor():\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation):\n",
    "        self.pi = mlp([obs_dim] + list(hidden_sizes) + [act_dim], activation)\n",
    "        self.obs_mean = np.ones(obs_dim)\n",
    "        self.obs_std = np.ones(obs_dim)\n",
    "        self.clip = 10.0\n",
    "        # print(type(self.pi))\n",
    "    \n",
    "    def normalize_o(self, o):\n",
    "        o = o - self.obs_mean\n",
    "        o = o / (self.obs_std + 1e-8)\n",
    "        o = np.clip(o, -self.clip, self.clip)\n",
    "        return o\n",
    "    \n",
    "    def act(self, o):\n",
    "        o = self.normalize_o(o)\n",
    "        o = torch.as_tensor(o, dtype=torch.float32)\n",
    "        return self.pi(o).detach().numpy()\n",
    "    \n",
    "    def copy_model(self, md):\n",
    "        self.pi.load_state_dict(md['pi'])\n",
    "        self.obs_mean = md['obs_mean']\n",
    "        self.obs_std = md['obs_std']\n",
    "        self.clip = md['clip']\n",
    "        \n",
    "    def load(self, name):\n",
    "        md = torch.load(name)\n",
    "        self.copy_model(md)\n",
    "\n",
    "\n",
    "def get_ppo_models(path, name):\n",
    "    fpath = osp.join(path, name)\n",
    "    models = []\n",
    "    file_names = os.listdir(fpath)\n",
    "    if len(file_names) == 0:\n",
    "        return []\n",
    "    env = gym.make(get_env_name(name))\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    for file_name in file_names:   \n",
    "        if \".pt\" not in file_name:\n",
    "            continue\n",
    "        fname = osp.join(fpath, file_name)\n",
    "        print(file_name)\n",
    "        model = PPO_Actor(obs_dim, action_dim, (64, 64), nn.Tanh)\n",
    "        model.load(fname)\n",
    "        models.append((name, file_name, model))\n",
    "    return models\n",
    "\n",
    "def get_models(path, name):\n",
    "    print(\"get models \", path, name)\n",
    "    if 'ppo' in name:\n",
    "        return get_ppo_models(path, name)\n",
    "    fpath = osp.join(path, name)\n",
    "    models = {}\n",
    "    file_names = os.listdir(fpath)\n",
    "    if len(file_names) == 0:\n",
    "        return []\n",
    "    for file_name in file_names:   \n",
    "        # fname = osp.join(fpath, file_name ,'pyt_save', 'model0.pt')\n",
    "        fname = osp.join(fpath, file_name ,'pyt_save', 'model.pt')\n",
    "        print(fname)\n",
    "        model = torch.load(fname)\n",
    "        models[file_name] = model\n",
    "        # models.append((name, file_name, model))\n",
    "    return models\n",
    "\n",
    "def save_state(env):\n",
    "    return env.sim.get_state()\n",
    "\n",
    "def restore_state(env, old_state):\n",
    "    env.reset()\n",
    "    env.sim.set_state(old_state)\n",
    "    env.sim.forward()\n",
    "    return env.get_obs()\n",
    "\n",
    "def get_ppo_action(o, md):\n",
    "    return md.act(o)\n",
    "\n",
    "def get_action(o, md, name):\n",
    "    if 'ppo' in name:\n",
    "        return get_ppo_action(o, md)\n",
    "    if 'train' not in name:\n",
    "        o = torch.as_tensor(o, dtype=torch.float32)\n",
    "        return md.act(o)\n",
    "    o = torch.as_tensor(o, dtype=torch.float32)\n",
    "    return md.act(o, deterministic=False)\n",
    "\n",
    "def get_q(o, a, md):\n",
    "    o = torch.as_tensor(o, dtype=torch.float32)\n",
    "    a = torch.as_tensor(a, dtype=torch.float32)\n",
    "    q1 = md.q1(o, a)\n",
    "    q2 = md.q2(o, a)\n",
    "    return torch.min(q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_traj_names_with_same_env(path, trajs_path, name):\n",
    "    all_trajs_names = []\n",
    "    fpath = osp.join(path, trajs_path)\n",
    "    print(fpath)\n",
    "    file_names = os.listdir(fpath)\n",
    "    if len(file_names) == 0:\n",
    "        return []\n",
    "    env_name = get_env_name(name)\n",
    "    for file_name in file_names:\n",
    "        if \"trajs.pkl\" not in file_name:\n",
    "            continue\n",
    "        tmp = get_env_name(file_name)\n",
    "        if tmp == env_name:\n",
    "            all_trajs_names.append(file_name)\n",
    "    return all_trajs_names\n",
    "\n",
    "\n",
    "def load_all_same_env_results(cpath, env_name):\n",
    "    print('load continue results: ', cpath)\n",
    "    file_names = os.listdir(cpath)\n",
    "    rets = []\n",
    "    for file_name in file_names:\n",
    "        if \".pkl\" in file_name and get_env_name(file_name) == env_name:\n",
    "            print(file_name)\n",
    "            file_name = osp.join(cpath, file_name)\n",
    "            with open(file_name, 'rb') as f: \n",
    "                ret = pickle.load(f)\n",
    "            rets.append(ret)\n",
    "    return rets\n",
    "\n",
    "def is_fail(data):\n",
    "    if data[3][0]:\n",
    "        return 1.0\n",
    "    # if data[3][1] < 100:\n",
    "    #     return 1.0\n",
    "    return 0.0\n",
    "\n",
    "def get_fail_rate(result): # result of one agent to one agent's trajs\n",
    "    ret = 0\n",
    "    for data in result:\n",
    "        ret += is_fail(data)\n",
    "    return ret/len(result)\n",
    "\n",
    "def get_result_mean(result):\n",
    "    ret = 0\n",
    "    for data in result: # data = (traj_id, midpoint_id, old_ret, (d, total_r))\n",
    "        ret += data[3][1]\n",
    "    return ret/len(result)\n",
    "\n",
    "def get_traj_d(path, trajs_path, all_traj_names, algo_names, test_algo_name):\n",
    "    env_name = get_env_name(test_algo_name)\n",
    "    trajs_d = {}\n",
    "    for aname in algo_names[env_name]:\n",
    "        for trajs_name in all_traj_names:\n",
    "            if aname in trajs_name:\n",
    "                tname = osp.join(path, trajs_path, trajs_name)\n",
    "                print(tname)\n",
    "                with open(tname, 'rb') as f: \n",
    "                    trajs = pickle.load(f)\n",
    "                trajs_d[aname] = trajs \n",
    "                break\n",
    "    return trajs_d\n",
    "\n",
    "def get_state(trajs_d, algo_name, agent_name, traj_id, midpoint_id):\n",
    "    for data in trajs_d[algo_name]:\n",
    "        if data[1] == agent_name:\n",
    "            return data[-1][traj_id][midpoint_id]\n",
    "\n",
    "def get_self_ret(cresults, trajs_d):\n",
    "    self_ret = {}\n",
    "    for algo_results in cresults:\n",
    "        for results in algo_results:\n",
    "            if results[0] == results[2] and results[1] == results[3]:\n",
    "                x = {}\n",
    "                for data in results[4]:\n",
    "                    if not data[3][0]:\n",
    "                        eplen, s = get_state(trajs_d, results[0], results[1], data[0], data[1])\n",
    "                        x[(data[0], data[1])] = (data[3][1],s, eplen)\n",
    "                        \n",
    "                if results[0] not in self_ret.keys():\n",
    "                    self_ret[results[0]] = {}\n",
    "                    print(results[0])\n",
    "                self_ret[results[0]][results[1]] = x\n",
    "    return self_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = '/home/lclan/spinningup/data/'\n",
    "trajs_path = 'trajs'\n",
    "continue_path = '/home/lclan/spinningup/data/tmp/'\n",
    "algo_names = {}\n",
    "algo_names['Humanoid-v3'] = ['Humanoid-v3_sac_base', 'Humanoid-v3_td3_base', 'vanilla_ppo_humanoid',  'sgld_ppo_humanoid']\n",
    "algo_names['Ant-v3'] = ['Ant-v3_sac_base' , 'Ant-v3_td3_base', 'vanilla_ppo_ant', 'atla_ppo_ant']\n",
    "algo_names['Walker2d-v3'] = ['Walker2d-v3_sac_base', 'Walker2d-v3_td3_base', 'vanilla_ppo_walker', 'atla_ppo_walker']\n",
    "algo_names['HalfCheetah-v3'] = ['HalfCheetah-v3_sac_base', 'HalfCheetah-v3_td3_base',  'vanilla_ppo_halfcheetah', 'atla_ppo_halfcheetah']\n",
    "algo_names['Hopper-v3'] = ['Hopper-v3_sac_base', 'Hopper-v3_td3_base', 'vanilla_ppo_hopper',  'atla_ppo_hopper']\n",
    "env_names = list(algo_names.keys())\n",
    "test_algo_name = 'Humanoid-v3_gsac_base'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lclan/spinningup/data/trajs\n",
      "['Humanoid-v3_td3_base_400_trajs.pkl', 'Humanoid-v3_sac_base_400_trajs.pkl', 'sgld_ppo_humanoid_400_trajs.pkl', 'vanilla_ppo_humanoid_400_trajs.pkl']\n"
     ]
    }
   ],
   "source": [
    "all_traj_names = get_all_traj_names_with_same_env(path, trajs_path, test_algo_name)\n",
    "print(all_traj_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load continue results:  /home/lclan/spinningup/data/tmp/\n",
      "Humanoid-v3_sac_base_s500_tr50_tn200.pkl\n",
      "sgld_ppo_humanoid_s500_tr50_tn200.pkl\n",
      "vanilla_ppo_humanoid_s500_tr50_tn200.pkl\n",
      "Humanoid-v3_td3_base_s500_tr50_tn200.pkl\n"
     ]
    }
   ],
   "source": [
    "cresults = load_all_same_env_results(continue_path, get_env_name(test_algo_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lclan/spinningup/data/trajs/Humanoid-v3_sac_base_400_trajs.pkl\n",
      "/home/lclan/spinningup/data/trajs/Humanoid-v3_td3_base_400_trajs.pkl\n",
      "/home/lclan/spinningup/data/trajs/vanilla_ppo_humanoid_400_trajs.pkl\n",
      "/home/lclan/spinningup/data/trajs/sgld_ppo_humanoid_400_trajs.pkl\n"
     ]
    }
   ],
   "source": [
    "trajs_d = get_traj_d(path, trajs_path, all_traj_names, algo_names, test_algo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humanoid-v3_sac_base\n",
      "sgld_ppo_humanoid\n",
      "vanilla_ppo_humanoid\n",
      "Humanoid-v3_td3_base\n"
     ]
    }
   ],
   "source": [
    "self_ret = get_self_ret(cresults, trajs_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get models  /home/lclan/spinningup/data/ Humanoid-v3_gsac_base\n",
      "/home/lclan/spinningup/data/Humanoid-v3_gsac_base/Humanoid-v3_gsac_base_s1124/pyt_save/model.pt\n",
      "/home/lclan/spinningup/data/Humanoid-v3_gsac_base/Humanoid-v3_gsac_base_s1125/pyt_save/model.pt\n"
     ]
    }
   ],
   "source": [
    "test_models = get_models(path, test_algo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sgld_ppo_humanoid_1.pt', 'sgld_ppo_humanoid_2.pt', 'sgld_ppo_humanoid_11.pt', 'sgld_ppo_humanoid_10.pt', 'sgld_ppo_humanoid_4.pt', 'sgld_ppo_humanoid_7.pt', 'sgld_ppo_humanoid_8.pt', 'sgld_ppo_humanoid_6.pt', 'sgld_ppo_humanoid_5.pt', 'sgld_ppo_humanoid_9.pt'])\n"
     ]
    }
   ],
   "source": [
    "print(self_ret['sgld_ppo_humanoid'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lclan/anaconda3/envs/rob_sac/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start testing on  Humanoid-v3_sac_base\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b49226f321da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_algo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-b49226f321da>\u001b[0m in \u001b[0;36mtest_models\u001b[0;34m(self_ret, test_models, test_algo_name, test_num, step_num)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start testing on \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_algo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself_ret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_algo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0morig_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meplen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_ret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_algo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mrestore_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "def run_extra_steps(env, ep_len, md, md_name, step_num=50):\n",
    "    max_ep_len = 1000\n",
    "    total_r = 0\n",
    "    o = env.get_obs()\n",
    "    for i in range(step_num):\n",
    "        a = get_action(o, md, md_name)\n",
    "        o, r, d, _ = env.step(a)\n",
    "        total_r += r\n",
    "        ep_len += 1\n",
    "        if d or (ep_len == max_ep_len):\n",
    "            return (d, total_r)\n",
    "    return (d, total_r)\n",
    "\n",
    "def test_models(self_ret, test_models, test_algo_name, test_num = 200, step_num = 500):\n",
    "    ret = {}\n",
    "    env_name = get_env_name(test_algo_name)\n",
    "    env = gym.make(env_name)\n",
    "    for gen_algo in self_ret.keys():\n",
    "        score = []\n",
    "        fail = []\n",
    "        print(\"start testing on \", gen_algo)\n",
    "        for k in self_ret[gen_algo].keys():\n",
    "            cnt = 0\n",
    "            for k2 in self_ret[gen_algo][k].keys():\n",
    "                orig_ret, s, eplen = self_ret[gen_algo][k][k2]\n",
    "                for md in test_models:\n",
    "                    restore_state(env, s)\n",
    "                    d, r = run_extra_steps(env, eplen, md, test_algo_name, step_num)\n",
    "                    fail.append(int(d))\n",
    "                    score.append(r)\n",
    "                cnt += 1\n",
    "                if cnt > test_num:\n",
    "                    break\n",
    "        ret[gen_algo] = (score, fail)\n",
    "    return ret\n",
    "\n",
    "score, fail = test_models(self_ret, test_models, test_algo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d07456bc64aaa948bb07d8fc241a93772a319883e604e16666e0b6e2246aebd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('rob_sac': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
